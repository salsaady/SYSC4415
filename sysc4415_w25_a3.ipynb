{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salsaady/SYSC4415/blob/main/sysc4415_w25_a3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcaEf9LdAu9k"
      },
      "source": [
        "# Welcome to Assignment 3\n",
        "\n",
        "**TA: [Igor Bogdanov](mailto:igorbogdanov@cmail.carleton.ca)**\n",
        "\n",
        "## General Instructions:\n",
        "\n",
        "This Assignment can be done **in a group of two or individually**.\n",
        "\n",
        "YOU HAVE TO JOIN A GROUP ON BRIGHTSPACE TO SUBMIT.\n",
        "\n",
        "Please state it explicitly at the beginning of the assignment.\n",
        "\n",
        "You need only one submission if it's group work.\n",
        "\n",
        "Please print out values when asked using Python's print() function with f-strings where possible.\n",
        "\n",
        "Submit your **saved notebook with all the outputs** to Brightspace, but ensure it will produce correct outputs upon restarting and click \"runtime\" → \"run all\" with clean outputs. Ensure your notebook displays all answers correctly.\n",
        "\n",
        "## Your Submission MUST contain your signature at the bottom.\n",
        "\n",
        "### Objective:\n",
        "In this assignment, we build a reasoning AI agent that facilitates ML operations and model evaluation. This assignment is heavily based on Tutorial 9.\n",
        "\n",
        "**Submission:** Submit your Notebook as a *.ipynb* file that adopts this naming convention: ***SYSC4415_W25_A3_NameLastname.ipynb*** on *Brightspace*. No other submission (e.g., through email) will be accepted. (Example file name: SYSC4415_W25_A3_IgorBogdanov.ipynb or SYSC4415_W25_A3_Student1_Student2.ipynb) The notebool MUST contain saved outputs\n",
        "\n",
        "**Runtime tips:**\n",
        "Agentic programming and API calling can be easily done locally and moved to Colab in the final stages, depending on the implementation of your tools and ML tasks you want to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIzWURYdCos_"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyRG5AEHNILq"
      },
      "source": [
        "Some basic libraries you need are imported here. Make sure you include whatever library you need in this entire notebook in the code block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXYKklNMNpbQ"
      },
      "source": [
        "If you are using any library that requires installation, please paste the installation command here.\n",
        "Leave the code block below if you are not installing any libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZEeRARqqPp8"
      },
      "outputs": [],
      "source": [
        "# Name: Sarah Al-Saady\n",
        "# Student Number: 101226759\n",
        "\n",
        "# Name:\n",
        "# Student Number:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxZ_P9tNkln"
      },
      "outputs": [],
      "source": [
        "# Libraries to install - leave this code block blank if this does not apply to you\n",
        "# Please add a brief comment on why you need the library and what it does\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t3_N_y3sNfTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8386c491-db21-4d6a-ddd1-f969c73aa581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "\n",
        "# Libraries you might need\n",
        "# General\n",
        "import os\n",
        "import zipfile\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# For pre-processing\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# For modeling\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchsummary\n",
        "\n",
        "# For metrics\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import  precision_score\n",
        "from sklearn.metrics import  recall_score\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import  classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import  roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Agent\n",
        "from groq import Groq\n",
        "from dataclasses import dataclass\n",
        "import re\n",
        "from typing import Dict, List, Optional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vX4Z_nNI6BY"
      },
      "source": [
        "# Task 1: Registration and API Activation (5 marks)\n",
        "\n",
        "For this particular assignment, we will be using GroqCloud for LLM inference. This task aims to determine how to use the Groq API with LLMs.  \n",
        "\n",
        "Create a free account on https://groq.com/ and generate an API Key. Don't remove your key until you get your grade. Feel free to delete your API key after the term is completed.\n",
        "\n",
        "In conversational AI, prompting involves three key roles: the system role (which sets the agent's behavior and capabilities), the user role (which represents human inputs and queries), and the assistant role (which contains the agent's responses). The system role provides the foundational instructions and constraints, the user role delivers the actual queries or commands, and the assistant role generates contextual, step-by-step responses following the system's guidelines. This structured approach ensures consistent, controlled interactions where the agent maintains its defined behavior while responding to user needs, with each role serving a specific purpose in the conversation flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5tSc4kOsghn_"
      },
      "outputs": [],
      "source": [
        "# Q1a (2 mark)\n",
        "# Create a client using your API key.\n",
        "\n",
        "client = Groq(api_key=\"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\")\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KT-vxP0QI74n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "07b52dfc-ad70-4522-9265-636394972114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Los Angeles Dodgers won the 2020 World Series, defeating the Tampa Bay Rays in the series 4 games to 2. This was the Dodgers' first World Series title since 1988. The final game was played on October 27, 2020, at Globe Life Field in Arlington, Texas.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Q1b (3 marks)\n",
        "\n",
        "# instantiate chat_completion object using model of your choice (llama-3.3-70b-versatile - recommended)\n",
        "# Hint: Use Tutorial 9 and Groq Documentation\n",
        "# Explain each parameter and how each value change influences the LLM's output.\n",
        "# Prompt the model using the user role about anything different from the tutorial.\n",
        "\n",
        "# YOUR ANSWER GOES HERE\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\", # ID of the model to use\n",
        "    temperature=0.2, # What sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic\n",
        "    top_p=0.7, # An alternative to sampling, the model considers the results of the tokens with top_p probability mass.\n",
        "                # This influences the models output, for ex. if it's 0.1, only the top 10% probability mass tokens are considered.\n",
        "    max_tokens=1024, # The maximum number of tokens that can be generated in the chat completion.\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}],\n",
        "        # A list of messages comprimising the conversation so far.\n",
        "    )\n",
        "\n",
        "chat_completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2f2stNqCmP_"
      },
      "source": [
        "# Task 2: Agent Implementation (5 marks)\n",
        "\n",
        "This task contains an implementation of the agent from Tutorial 9. The idea of this task is to make sure you understand how basic LLM-Agent works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "feUcU4mCl2rn"
      },
      "outputs": [],
      "source": [
        "# Q2a: (5 marks) Explain how agent implementation works, providing comments line by line.\n",
        "# This paper might be helpful: https://react-lm.github.io/\n",
        "\n",
        "# Agent state class holds the state of the agent\n",
        "@dataclass\n",
        "class Agent_State:\n",
        "    messages: List[Dict[str, str]] # list of dictionaries\n",
        "    system_prompt: str # prompt for the system\n",
        "\n",
        "# Actual agent class\n",
        "class ML_Agent:\n",
        "    # Initializes an instance of the agent and initializes an agent state with a prompt\n",
        "    def __init__(self, system_prompt: str):\n",
        "        self.client = client # API client\n",
        "        self.state = Agent_State(\n",
        "            messages=[{\"role\": \"system\", \"content\": system_prompt}], # sets the agent state with a system message containing the prompt\n",
        "            system_prompt=system_prompt,\n",
        "        )\n",
        "\n",
        "    # Adds a message to the agent's past list of messages (conversation history)\n",
        "    def add_message(self, role: str, content: str) -> None:\n",
        "        self.state.messages.append({\"role\": role, \"content\": content}) # add to the dictionary the role and content\n",
        "\n",
        "    # This is the reasoning\n",
        "    def execute(self) -> str:\n",
        "        # Send the conversation history to the LLM API\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            temperature=0.2,\n",
        "            top_p=0.7, # limit token sampling to the top 70% probability mass\n",
        "            max_tokens=1024,\n",
        "            messages=self.state.messages, # provide the full conversation history as context\n",
        "        )\n",
        "        return completion.choices[0].message.content # return the generated response\n",
        "\n",
        "    # when the agent class is invoked, this is called (callable function)\n",
        "    def __call__(self, message: str) -> str:\n",
        "        self.add_message(\"user\", message) # add the user's question (message) to the conversation\n",
        "        result = self.execute() # start reasoning (thought), generates assistant's response\n",
        "        self.add_message(\"assistant\", result) # add the answer from the assistant to the conversation\n",
        "        return result # return the assistant's response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3eOrZAElyrH"
      },
      "source": [
        "# Task 3: Tools (20 marks)\n",
        "\n",
        "Tools are specialized functions that enable AI agents to perform specific actions beyond their inherent capabilities, such as retrieving information, performing calculations, or manipulating data. Agents use tools to decompose complex reasoning into observable steps, extend their knowledge beyond training data, maintain state across interactions, and provide transparency in their decision-making process, ultimately allowing them to solve problems they couldn't tackle through reasoning alone.\n",
        "\n",
        "Essentially, tools are just callback functions invoked by the agent at the appropriate time during the execution loop.\n",
        "\n",
        "You need to plan your tools for each particular task your agent is expected to solve.\n",
        "The Model Evaluation Agent we are building should be able to evaluate the model from the model pool on the specific dataset.\n",
        "\n",
        "Datasets to use: Penguins, Iris, CIFAR-10\n",
        "\n",
        "You should be able to tell the agent what to do and watch it display the output of the tools' execution, similar to that in Tutorial 9.\n",
        "\n",
        "User Prompt examples you should be able to give to your agent and expect it to fulfill the task:\n",
        "- **Evaluate Linear Regression Model on Iris Dataset**\n",
        "- **Train a logistic regression model on the Iris dataset**\n",
        "- **Load the Penguins dataset and preprocess it.**\n",
        "- **Train a decision tree model on the Penguins dataset and evaluate it.**\n",
        "- **Load the CIFAR-10 dataset and train Mini-ResNet CNN, visualize results**\n",
        "\n",
        "Classifier Models for Iris and Penguins (use A1 and early tutorials):\n",
        "  * Logistic Regression (solver='lbfgs')\n",
        "  * Decision Tree (max_depth=3)\n",
        "  * KNN (n_neighbors=5)\n",
        "\n",
        "Any 2 CNN models of your choice for CIFAR-10 dataset (do some research, don't create anything from scratch unless you want to, use the ones provided by libraries and frameworks)\n",
        "\n",
        "HINT: It is highly recommended that any code from previous assignments and tutorials be reused for tool implementation.\n",
        "\n",
        "**Use Pytorch where possible**\n",
        "\n",
        "## DON'T FORGET TO IMPORT MISSING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnqADgZqqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3a (3 marks): Implement model_memory tool.\n",
        "# This tool should provide the agent with details about models or datasets\n",
        "# Example: when asked about Penguin dataset, the agent can use memory to look up\n",
        "# the source to obtain the dataset.\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sPHHfdVqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3b (3 marks): Implement dataset_loader tool.\n",
        "# loads dataset after obtaining info from memory\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNpzf3LSqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3c (3 marks): Implement dataset_preprocessing tool.\n",
        "# preprocesses the dataset to work with the chosen model, and does the splits\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdsyTSp_qPp9"
      },
      "outputs": [],
      "source": [
        "# Q3d (3 points): Implement train_model tool.\n",
        "# trains selected model on selected dataset, the agent should not use this tool\n",
        "# on datasets and models that cannot work together.\n",
        "\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PwGEcq3qPp9"
      },
      "outputs": [],
      "source": [
        "# Q3e (3 marks): Implement evaluate_model tool\n",
        "# evaluates the models and shows the quality metrics (accuracy, precision, and anything else of your choice)\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWdsndGrqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3f (5 marks): Implement visualize_results tool\n",
        "# provides results of the training/evaluation, open-ended task (2 plots minimum)\n",
        "\n",
        "\n",
        "# YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyY4lATzCmsf"
      },
      "source": [
        "# Task 4: System Prompt (10 marks)\n",
        "A system prompt is essential for guiding an agent's behavior by establishing its purpose, capabilities, tone, and workflow patterns. It acts as the \"personality and instruction manual\" for the agent, defining the format of interactions (like using Thought/Action/Observation steps in our ML agent), available tools, response styles, and domain-specific knowledge—all while remaining invisible to the end user. This hidden layer of instruction ensures the agent consistently follows the intended reasoning process and operational constraints while providing appropriate and helpful responses, effectively serving as the blueprint for the agent's behavior across all interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCq6n5_FjJef"
      },
      "outputs": [],
      "source": [
        "# Q4a (10 marks) Build a system prompt to guide the agent based on Tutorial 9.\n",
        "# Use the following function:\n",
        "\n",
        "# Try to find alternative wording to keep the agent in the desired loop,\n",
        "# don't just copy the prompt from the tutorial.\n",
        "\n",
        "# Penalty for direct copy - 2 marks\n",
        "\n",
        "def create_agent():\n",
        "    # your system prompt goes inside the multiline string\n",
        "    system_prompt = \"\"\"\n",
        "\n",
        "    \"\"\".strip()\n",
        "\n",
        "    return ML_Agent(system_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T16yokijI2P"
      },
      "source": [
        "# Task 5: Set the Agent Loop (10 marks)\n",
        "\n",
        "Now we are building automation of our Thought/Action/Observation sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q82GuUEmcewk"
      },
      "outputs": [],
      "source": [
        "# Q5a: (2 marks) Explain why we need the following data structure and fill it in with appropriate values:\n",
        "KNOWN_ACTIONS = {\n",
        "   # HINT See Tutorial 9.\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7A5XTqrCnCf"
      },
      "outputs": [],
      "source": [
        "# Q5b: (6 marks) Explain how the agent automation loop works line by line. Why do we need the ACTION_PATTERN variable?\n",
        "# This paper might be helpful: https://react-lm.github.io/\n",
        "\n",
        "ACTION_PATTERN = re.compile(\"^Action: (\\w+): (.*)$\")\n",
        "\n",
        "number_of_steps = 5 # adjust this number for your implementation, to avoid an infinite loop\n",
        "\n",
        "def query(question: str, max_turns: int = number_of_steps) -> List[Dict[str, str]]:\n",
        "    agent = create_agent()\n",
        "    next_prompt = question\n",
        "\n",
        "    for turn in range(max_turns):\n",
        "        result = agent(next_prompt)\n",
        "        print(result)\n",
        "        actions = [\n",
        "            ACTION_PATTERN.match(a)\n",
        "            for a in result.split(\"\\n\")\n",
        "            if ACTION_PATTERN.match(a)\n",
        "        ]\n",
        "        if actions:\n",
        "            action, action_input = actions[0].groups()\n",
        "            if action not in KNOWN_ACTIONS:\n",
        "                raise ValueError(f\"Unknown action: {action}: {action_input}\")\n",
        "            print(f\"\\n ---> Executing {action} with input: {action_input}\")\n",
        "            observation = KNOWN_ACTIONS[action](action_input)\n",
        "            print(f\"Observation: {observation}\")\n",
        "            next_prompt = f\"Observation: {observation}\"\n",
        "        else:\n",
        "            break\n",
        "    return agent.state.messages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z33PNv77iwN_"
      },
      "outputs": [],
      "source": [
        "# Q5b: (2 marks)\n",
        "# QUESTION: How can we check the whole history of the agent's interaction with LLM?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8F2uGS_qPp-"
      },
      "source": [
        "# Task 6: Run your agent (15 marks)\n",
        "\n",
        "Let's see if your agent works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tfBsrMqiwLf"
      },
      "outputs": [],
      "source": [
        "# Execute any THREE example prompts using your agent. (Each working prompt exaple will give you 5 marks, 5x3=15)\n",
        "# DONT FORGET TO SAVE THE OUTPUT\n",
        "\n",
        "# User Prompt examples you should be able to give to your agent:\n",
        "# **Evaluate Linear Regression Model on Iris Dataset**\n",
        "# **Train a logistic regression model on the Iris dataset**\n",
        "# **Load the Penguins dataset and preprocess it.**\n",
        "# **Train a decision tree model on the Penguins dataset and evaluate it.**\n",
        "# **Load the CIFAR-10 dataset and train Mini-ResNet CNN, visualize results**\n",
        "\n",
        "# Use this template:\n",
        "\n",
        "# Example 1: Prompt\n",
        "print(\"\\nExample 1: Evaluate Linear Regression Model on Iris Dataset\")\n",
        "print(\"=\" * 50)\n",
        "task = \"Evaluate Linear Regression Model on Iris Dataset\"\n",
        "result = query(task)\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYQihPdOuCcc"
      },
      "source": [
        "# Task 7: BONUS (10 points)\n",
        "Not valid without completion of all the previous tasks and tool implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10N4ZEGjiwIv"
      },
      "outputs": [],
      "source": [
        "# Build your own additional ML-related tool and provide an example of interaction with your reasoning agent\n",
        "# using a prompt of your choice that makes the agent use your tool at one of the reasoning steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG9_BGQrG1go"
      },
      "source": [
        "Good luck!\n",
        "\n",
        "## Signature:\n",
        "Don't forget to insert your name and student number and execute the snippet below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKSDTADVqPp-"
      },
      "outputs": [],
      "source": [
        "!pip install watermark\n",
        "# Provide your Signature:\n",
        "%load_ext watermark\n",
        "%watermark -a 'Your Name, #Student_Number' -nmv --packages numpy,pandas,sklearn,matplotlib,seaborn,graphviz,groq,torch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}